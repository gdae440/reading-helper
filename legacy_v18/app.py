import streamlit as st
from openai import OpenAI
import edge_tts
from gtts import gTTS
import asyncio
import json
import os
import io
import base64
import re
import random
from datetime import datetime
from PIL import Image
import genanki
from streamlit_option_menu import option_menu

# ================= 1. æ ¸å¿ƒé…ç½®ä¸å·¥å…·å‡½æ•° =================

VOCAB_FILE = "my_vocab.json"

def load_vocab():
    """åŠ è½½ç”Ÿè¯æœ¬"""
    # å…¼å®¹ä¸åŒè¿è¡Œç›®å½•
    paths = ["my_vocab.json", "../my_vocab.json"]
    for p in paths:
        if os.path.exists(p):
            try:
                return json.load(open(p, "r", encoding="utf-8"))
            except:
                pass
    return []

def save_vocab(vocab_list):
    """ä¿å­˜ç”Ÿè¯æœ¬"""
    try:
        with open(VOCAB_FILE, "w", encoding="utf-8") as f:
            json.dump(vocab_list, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"ä¿å­˜å¤±è´¥: {e}")

def get_smart_filename(text):
    """ç”Ÿæˆæ™ºèƒ½æ–‡ä»¶å"""
    if not text: return f"audio_{datetime.now().strftime('%H%M%S')}.mp3"
    snippet = text[:20]
    safe_name = re.sub(r'[^\w\s\u4e00-\u9fa5-]', '', snippet).strip()
    safe_name = re.sub(r'[\s]+', '_', safe_name)
    return f"{safe_name}.mp3" if safe_name else "audio.mp3"

# ================= 2. é¡µé¢åˆå§‹åŒ–ä¸æ ·å¼ =================

st.set_page_config(page_title="è·Ÿè¯»åŠ©æ‰‹ Pro (Legacy)", layout="wide", page_icon="ğŸ“˜")

# Apple Design é£æ ¼ CSS
st.markdown("""
<style>
    /* å…¨å±€èƒŒæ™¯ä¸å­—ä½“ */
    .stApp {
        background-color: #f5f5f7;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    }
    /* æŒ‰é’®ä¼˜åŒ– */
    .stButton > button {
        border-radius: 10px;
        border: none;
        font-weight: 500;
        transition: all 0.2s;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
    }
    .stButton > button:hover {
        transform: translateY(-1px);
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    /* ä¸»æŒ‰é’®è“è‰² */
    button[kind="primary"] {
        background-color: #007aff !important;
        color: white !important;
    }
    /* ä¾§è¾¹æ æ ·å¼ */
    section[data-testid="stSidebar"] {
        background-color: #ffffff;
        border-right: 1px solid #e5e5ea;
    }
    /* æŸ¥è¯å¡ç‰‡ */
    div.lookup-card {
        background: white;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 15px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.04);
        border: 1px solid #e5e5ea;
    }
</style>
""", unsafe_allow_html=True)

# ================= 3. çŠ¶æ€ç®¡ç† (Session State) =================

if 'cfg' not in st.session_state:
    st.session_state.cfg = {
        "api_key": os.getenv("SILICON_KEY", ""),
        "engine": "Edge (æ¨è)",
        "voice_role": "en-US-AriaNeural",
        "speed": 0,
        "learn_lang": "ğŸ‡¬ğŸ‡§ è‹±è¯­",
        "chat_model": "deepseek-ai/DeepSeek-V3",
        "ocr_model": "Qwen/Qwen2.5-VL-72B-Instruct",
        "generic_base_url": "https://api.siliconflow.cn/v1"
    }

if 'vocab' not in st.session_state: st.session_state.vocab = load_vocab()
if 'main_text' not in st.session_state: st.session_state.main_text = ""
if 'trans_text' not in st.session_state: st.session_state.trans_text = ""
if 'audio_data' not in st.session_state: st.session_state.audio_data = None
if 'last_lookup' not in st.session_state: st.session_state.last_lookup = None
# éŸ³é¢‘ç¼“å­˜æ± ï¼Œé¿å…é‡ç»˜ä¸¢å¤±
if 'vocab_audio_cache' not in st.session_state: st.session_state.vocab_audio_cache = {}
if 'playing_word_idx' not in st.session_state: st.session_state.playing_word_idx = -1

# ================= 4. æ ¸å¿ƒ API é€»è¾‘ =================

def get_api_client(cfg):
    """è·å– OpenAI å…¼å®¹å®¢æˆ·ç«¯"""
    key = cfg.get("api_key")
    base_url = cfg.get("generic_base_url", "https://api.siliconflow.cn/v1")
    if not key: return None, "âŒ æœªé…ç½® API Key"
    # å®¹é”™å¤„ç†
    if not base_url.endswith("/v1"): 
        if base_url.endswith("/"): base_url += "v1"
        else: base_url += "/v1"
        
    return OpenAI(api_key=key, base_url=base_url), None

def api_call(task_type, content, cfg):
    """ç»Ÿä¸€ API è°ƒç”¨å…¥å£"""
    client, err = get_api_client(cfg)
    if not client: return None, err

    try:
        if task_type == "ocr":
            # å›¾ç‰‡è½¬ base64
            buffered = io.BytesIO()
            content.save(buffered, format="JPEG", quality=85)
            b64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
            res = client.chat.completions.create(
                model=cfg["ocr_model"],
                messages=[{
                    "role": "user", 
                    "content": [
                        {"type": "text", "text": "Recognize all text in this image. Output plain text only."}, 
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}
                    ]
                }]
            )
            return res.choices[0].message.content, None
            
        elif task_type == "lookup":
            # å¼ºåˆ¶ JSON æ¨¡å¼
            prompt = f"""Explain the word "{content}" concisely. Return strictly valid JSON format:
            {{ "detected_lang": "en", "ipa": "/.../", "zh": "Chinese definition", "ru": "Russian definition" }}"""
            res = client.chat.completions.create(
                model=cfg["chat_model"],
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            return json.loads(res.choices[0].message.content), None
            
        elif task_type == "trans":
            res = client.chat.completions.create(
                model=cfg["chat_model"],
                messages=[{"role": "user", "content": f"Translate the following text to natural Chinese:\n\n{content}"}]
            )
            return res.choices[0].message.content, None
            
    except Exception as e:
        return None, f"API Error: {str(e)}"
    return None, "Unknown Error"

async def get_audio_bytes_mixed(text, engine_type, voice_id, speed_int, cfg):
    """å¤šå¼•æ“ TTS æ ¸å¿ƒé€»è¾‘"""
    if not text: return None, "No text"
    
    # 1. Edge TTS (æœ€å¼ºå…è´¹)
    if "Edge" in engine_type:
        try:
            # é€Ÿåº¦è½¬æ¢: -50 -> -50%, +50 -> +50%
            rate_str = f"{speed_int:+d}%"
            communicate = edge_tts.Communicate(text, voice_id, rate=rate_str)
            mp3_fp = io.BytesIO()
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    mp3_fp.write(chunk["data"])
            return mp3_fp.getvalue(), None
        except Exception as e:
            return None, f"Edge TTS Error: {e}"

    # 2. SiliconFlow (CosyVoice)
    elif "SiliconFlow" in engine_type:
        client, err = get_api_client(cfg)
        if not client: return None, err
        model_id = "FunAudioLLM/CosyVoice2-0.5B" # å›ºå®šé»˜è®¤æ¨¡å‹
        # æå–å®é™… voice ä»£ç  (å¦‚æœå«æœ‰ model å‰ç¼€åˆ™å‰¥ç¦»)
        real_voice = voice_id.split(":")[-1] if ":" in voice_id else voice_id 
        
        try:
            # é€Ÿåº¦è½¬æ¢: 0 -> 1.0, 10 -> 1.1
            sf_speed = 1.0 + (speed_int / 100.0)
            response = client.audio.speech.create(
                model=model_id,
                voice=model_id + ":" + real_voice, # SF æ ¼å¼è¦æ±‚
                input=text,
                speed=sf_speed
            )
            return response.content, None
        except Exception as e:
            return None, f"SiliconFlow TTS Error: {e}"

    # 3. Google (gTTS)
    elif "Google" in engine_type:
        try:
            # è¯­è¨€ä»£ç æ˜ å°„
            lang_map = {"ğŸ‡¬ğŸ‡§ è‹±è¯­": "en", "ğŸ‡«ğŸ‡· æ³•è¯­": "fr", "ğŸ‡©ğŸ‡ª å¾·è¯­": "de", "ğŸ‡·ğŸ‡º ä¿„è¯­": "ru"}
            lang_code = lang_map.get(cfg["learn_lang"], "en")
            tts = gTTS(text=text, lang=lang_code)
            mp3_fp = io.BytesIO()
            tts.write_to_fp(mp3_fp)
            return mp3_fp.getvalue(), None
        except Exception as e:
            return None, f"Google TTS Error: {e}"
            
    return None, "Unknown Engine"

async def create_anki_package(selected_items, cfg):
    """ç”Ÿæˆ Anki åŒ…"""
    deck = genanki.Deck(random.randrange(1<<30, 1<<31), 'è·Ÿè¯»åŠ©æ‰‹ç”Ÿè¯æœ¬')
    model = genanki.Model(
        random.randrange(1<<30, 1<<31),
        'Simple Model',
        fields=[{'name': 'Question'}, {'name': 'Answer'}, {'name': 'Audio'}],
        templates=[{
            'name': 'Card 1',
            'qfmt': '<div style="font-size:24px;text-align:center">{{Question}}</div><br>{{Audio}}',
            'afmt': '{{FrontSide}}<hr id="answer"><div style="text-align:center">{{Answer}}</div>',
        }]
    )
    
    media_files = []
    temp_files = [] # ç”¨äºåç»­æ¸…ç†
    
    my_bar = st.progress(0, text="å‡†å¤‡ç”Ÿæˆ Anki åŒ…...")
    
    for idx, item in enumerate(selected_items):
        my_bar.progress((idx + 1) / len(selected_items), text=f"å¤„ç†: {item['word']}")
        
        # è‡ªåŠ¨åŒ¹é…å‘éŸ³è§’è‰²
        v_role = "en-US-AriaNeural"
        if "ru" in str(item): v_role = "ru-RU-DmitryNeural"
        elif "fr" in str(item): v_role = "fr-FR-HenriNeural"
        
        # ç”ŸæˆéŸ³é¢‘
        aud_data, _ = await get_audio_bytes_mixed(item['word'], "Edge (æ¨è)", v_role, 0, cfg)
        
        audio_field = ""
        if aud_data:
            fname = f"anki_{random.randint(1000,9999)}_{idx}.mp3"
            with open(fname, "wb") as f:
                f.write(aud_data)
            media_files.append(fname)
            temp_files.append(fname)
            audio_field = f"[sound:{fname}]"
            
        note = genanki.Note(
            model=model,
            fields=[
                f"{item['word']} <br> <small style='color:grey'>{item.get('ipa','')}</small>",
                f"ğŸ‡¨ğŸ‡³ {item.get('zh','')}<br>ğŸ‡·ğŸ‡º {item.get('ru','')}",
                audio_field
            ]
        )
        deck.add_note(note)

    pkg = genanki.Package(deck)
    pkg.media_files = media_files
    
    out_io = io.BytesIO()
    pkg.write_to_file(out_io)
    out_io.seek(0)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    for f in temp_files:
        if os.path.exists(f): os.remove(f)
        
    my_bar.empty()
    return out_io

# ================= 5. ä¾§è¾¹æ è®¾ç½® =================

with st.sidebar:
    st.title("ğŸ“˜ è·Ÿè¯»åŠ©æ‰‹ Pro")
    
    # å¯¼èˆªèœå•
    selected_page = option_menu(
        menu_title=None,
        options=["å­¦ä¹ ä¸»é¡µ", "å•è¯æœ¬", "é«˜çº§è®¾ç½®"],
        icons=['book', 'journal-bookmark', 'gear'],
        default_index=0,
        styles={"nav-link": {"font-size": "15px", "margin": "5px"}}
    )
    
    st.divider()
    
    # è¯­éŸ³è®¾ç½®å¡ç‰‡
    with st.expander("ğŸ”Š è¯­éŸ³ä¸è¯­è¨€è®¾ç½®", expanded=True):
        # è¯­è¨€é€‰æ‹©
        lang_options = ["ğŸ‡¬ğŸ‡§ è‹±è¯­", "ğŸ‡«ğŸ‡· æ³•è¯­", "ğŸ‡©ğŸ‡ª å¾·è¯­", "ğŸ‡·ğŸ‡º ä¿„è¯­"]
        current_lang = st.session_state.cfg.get("learn_lang", "ğŸ‡¬ğŸ‡§ è‹±è¯­")
        # é˜²æ­¢ index out of range
        idx = lang_options.index(current_lang) if current_lang in lang_options else 0
        new_lang = st.selectbox("å­¦ä¹ è¯­è¨€", lang_options, index=idx)
        
        if new_lang != current_lang:
            st.session_state.cfg["learn_lang"] = new_lang
            # åˆ‡æ¢è¯­è¨€è‡ªåŠ¨é‡ç½®æ¨èäºº
            defaults = {
                "ğŸ‡¬ğŸ‡§ è‹±è¯­": "en-US-AriaNeural",
                "ğŸ‡«ğŸ‡· æ³•è¯­": "fr-FR-HenriNeural", 
                "ğŸ‡©ğŸ‡ª å¾·è¯­": "de-DE-ConradNeural",
                "ğŸ‡·ğŸ‡º ä¿„è¯­": "ru-RU-DmitryNeural"
            }
            st.session_state.cfg["voice_role"] = defaults.get(new_lang, "en-US-AriaNeural")
            st.rerun()

        # å¼•æ“é€‰æ‹©
        engine_opts = ["Edge (æ¨è)", "SiliconFlow", "Google"]
        curr_engine = st.session_state.cfg.get("engine", "Edge (æ¨è)")
        idx_e = engine_opts.index(curr_engine) if curr_engine in engine_opts else 0
        new_engine = st.selectbox("TTS å¼•æ“", engine_opts, index=idx_e)
        st.session_state.cfg["engine"] = new_engine
        
        # éŸ³è‰²é€‰æ‹©é€»è¾‘
        if "Edge" in new_engine:
            voice_map = {
                "ğŸ‡¬ğŸ‡§ è‹±è¯­": {"ğŸ‡ºğŸ‡¸ Aria (å¥³)": "en-US-AriaNeural", "ğŸ‡¬ğŸ‡§ Ryan (ç”·)": "en-GB-RyanNeural"},
                "ğŸ‡«ğŸ‡· æ³•è¯­": {"ğŸ‡«ğŸ‡· Henri (ç”·)": "fr-FR-HenriNeural", "ğŸ‡«ğŸ‡· Denise (å¥³)": "fr-FR-DeniseNeural"},
                "ğŸ‡©ğŸ‡ª å¾·è¯­": {"ğŸ‡©ğŸ‡ª Conrad (ç”·)": "de-DE-ConradNeural", "ğŸ‡©ğŸ‡ª Katja (å¥³)": "de-DE-KatjaNeural"},
                "ğŸ‡·ğŸ‡º ä¿„è¯­": {"ğŸ‡·ğŸ‡º Dmitry (ç”·)": "ru-RU-DmitryNeural", "ğŸ‡·ğŸ‡º Svetlana (å¥³)": "ru-RU-SvetlanaNeural"},
            }
            avail_voices = voice_map.get(new_lang, {"Default": "en-US-AriaNeural"})
            v_names = list(avail_voices.keys())
            # åæŸ¥å½“å‰ voice å¯¹åº”çš„ name
            curr_role = st.session_state.cfg["voice_role"]
            default_idx = 0
            for i, (name, code) in enumerate(avail_voices.items()):
                if code == curr_role: default_idx = i
            
            sel_v = st.selectbox("é€‰æ‹©å‘éŸ³äºº", v_names, index=default_idx)
            st.session_state.cfg["voice_role"] = avail_voices[sel_v]
            
        elif "SiliconFlow" in new_engine:
            sf_voices = {
                "Benjamin (è‹±/ç”·)": "benjamin",
                "Bella (ç¾/å¥³)": "bella",
                "Alex (ç¾/ç”·)": "alex"
            }
            st.info("SiliconFlow ä»…æ”¯æŒéƒ¨åˆ†è‹±è¯­/ä¸­æ–‡éŸ³è‰²")
            sel_sf = st.selectbox("CosyVoice éŸ³è‰²", list(sf_voices.keys()))
            st.session_state.cfg["voice_role"] = sf_voices[sel_sf]

        st.session_state.cfg["speed"] = st.slider("è¯­é€Ÿ (Rate)", -50, 50, st.session_state.cfg["speed"], 10)

# ================= 6. ä¸»é¡µé¢é€»è¾‘ =================

if selected_page == "é«˜çº§è®¾ç½®":
    st.subheader("ğŸ› ï¸ ç³»ç»Ÿè®¾ç½®")
    
    with st.container(border=True):
        st.markdown("#### ğŸ”‘ API å¯†é’¥ç®¡ç†")
        st.session_state.cfg["api_key"] = st.text_input(
            "SiliconFlow API Key (ç”¨äº AI ç¿»è¯‘/æŸ¥è¯/TTS)", 
            value=st.session_state.cfg["api_key"], 
            type="password",
            help="ä» cloud.siliconflow.cn è·å–"
        )
        st.session_state.cfg["generic_base_url"] = st.text_input(
            "Base URL", 
            value=st.session_state.cfg["generic_base_url"]
        )
    
    with st.container(border=True):
        st.markdown("#### ğŸ§  æ¨¡å‹é…ç½®")
        c1, c2 = st.columns(2)
        with c1:
            st.session_state.cfg["chat_model"] = st.text_input("Chat æ¨¡å‹", value=st.session_state.cfg["chat_model"])
        with c2:
            st.session_state.cfg["ocr_model"] = st.text_input("OCR æ¨¡å‹", value=st.session_state.cfg["ocr_model"])

elif selected_page == "å­¦ä¹ ä¸»é¡µ":
    # ä¸¤æ å¸ƒå±€ï¼šå·¦ä¾§è¾“å…¥ï¼Œå³ä¾§æŸ¥è¯
    col_main, col_side = st.columns([2, 1])
    
    with col_main:
        st.markdown("### ğŸ“ é˜…è¯»ä¸æœ—è¯»")
        
        # è¾“å…¥æ–¹å¼åˆ‡æ¢
        input_tab1, input_tab2 = st.tabs(["âœï¸ æ–‡æœ¬è¾“å…¥", "ğŸ“· æ‹ç…§è¯†åˆ« (OCR)"])
        
        with input_tab1:
            txt = st.text_area("è¯·è¾“å…¥æ–‡ç« ", value=st.session_state.main_text, height=200, placeholder="Paste text here...")
            if st.button("æ›´æ–°æ–‡æœ¬", key="btn_update_txt"):
                st.session_state.main_text = txt
                st.session_state.trans_text = "" # æ¸…ç©ºæ—§ç¿»è¯‘
                st.rerun()
                
        with input_tab2:
            uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg'])
            if uploaded_file and st.button("å¼€å§‹ OCR è¯†åˆ«"):
                with st.spinner("æ­£åœ¨è¯†åˆ«æ–‡å­—..."):
                    res_text, err = api_call("ocr", Image.open(uploaded_file), st.session_state.cfg)
                    if res_text:
                        st.session_state.main_text = res_text
                        st.session_state.trans_text = ""
                        st.success("è¯†åˆ«æˆåŠŸï¼")
                        st.rerun()
                    else:
                        st.error(err)
        
        # æ“ä½œæ 
        if st.session_state.main_text:
            st.markdown("---")
            c1, c2, c3 = st.columns([1, 1, 2])
            with c1:
                if st.button("â–¶ï¸ æœ—è¯»å…¨æ–‡", type="primary", use_container_width=True):
                    with st.spinner("æ­£åœ¨åˆæˆè¯­éŸ³..."):
                        audio_data, err = asyncio.run(get_audio_bytes_mixed(
                            st.session_state.main_text,
                            st.session_state.cfg["engine"],
                            st.session_state.cfg["voice_role"],
                            st.session_state.cfg["speed"],
                            st.session_state.cfg
                        ))
                        if audio_data:
                            st.session_state.audio_data = audio_data
                            st.rerun()
                        else:
                            st.error(f"åˆæˆå¤±è´¥: {err}")
            
            with c2:
                if st.button("ğŸŒ å…¨æ–‡ç¿»è¯‘", use_container_width=True):
                    with st.spinner("AI ç¿»è¯‘ä¸­..."):
                        trans, err = api_call("trans", st.session_state.main_text, st.session_state.cfg)
                        if trans:
                            st.session_state.trans_text = trans
                            st.rerun()
                        else:
                            st.error(err)

            # ç»“æœå±•ç¤ºåŒº
            if st.session_state.trans_text:
                st.info(f"**å‚è€ƒè¯‘æ–‡ï¼š**\n\n{st.session_state.trans_text}")
            
            if st.session_state.audio_data:
                st.audio(st.session_state.audio_data, format="audio/mp3")
                # ä¸‹è½½æŒ‰é’®
                b64_audio = base64.b64encode(st.session_state.audio_data).decode()
                filename = get_smart_filename(st.session_state.main_text)
                href = f'<a href="data:audio/mp3;base64,{b64_audio}" download="{filename}" style="text-decoration:none;">ğŸ“¥ ç‚¹å‡»ä¸‹è½½éŸ³é¢‘</a>'
                st.markdown(href, unsafe_allow_html=True)

    with col_side:
        st.markdown("### ğŸ” æ™ºèƒ½æŸ¥è¯")
        with st.container(border=True):
            q_word = st.text_input("æŸ¥è¯", placeholder="è¾“å…¥å•è¯...")
            if st.button("æŸ¥è¯¢ & è§£æ", use_container_width=True):
                if q_word:
                    with st.spinner("æŸ¥è¯¢ä¸­..."):
                        info, err = api_call("lookup", q_word, st.session_state.cfg)
                        if info:
                            info['word'] = q_word # ç¡®ä¿æœ‰ word å­—æ®µ
                            st.session_state.last_lookup = info
                            # è‡ªåŠ¨ç”Ÿæˆå‘éŸ³
                            ab, _ = asyncio.run(get_audio_bytes_mixed(q_word, "Edge (æ¨è)", "en-US-AriaNeural", 0, st.session_state.cfg))
                            st.session_state.lookup_audio = ab
                            
                            # è‡ªåŠ¨åŠ å…¥ç”Ÿè¯æœ¬ (å»é‡)
                            if not any(w['word'] == q_word for w in st.session_state.vocab):
                                new_item = {
                                    "word": q_word,
                                    "ipa": info.get("ipa", ""),
                                    "zh": info.get("zh", ""),
                                    "ru": info.get("ru", ""),
                                    "date": datetime.now().strftime("%Y-%m-%d")
                                }
                                st.session_state.vocab.insert(0, new_item)
                                save_vocab(st.session_state.vocab)
                            st.rerun()
                        else:
                            st.error(err)

        # æ˜¾ç¤ºæŸ¥è¯ç»“æœå¡ç‰‡
        if st.session_state.last_lookup:
            info = st.session_state.last_lookup
            st.markdown(f"""
            <div class="lookup-card">
                <h3 style="color:#007aff; margin-bottom:0;">{info['word']}</h3>
                <div style="color:#666; font-family:monospace; margin-bottom:10px;">{info.get('ipa', '')}</div>
                <div style="margin-bottom:5px;"><b>ğŸ‡¨ğŸ‡³ ä¸­æ–‡ï¼š</b>{info.get('zh', 'N/A')}</div>
                <div><b>ğŸ‡·ğŸ‡º ä¿„è¯­ï¼š</b>{info.get('ru', 'N/A')}</div>
            </div>
            """, unsafe_allow_html=True)
            
            if st.session_state.lookup_audio:
                st.audio(st.session_state.lookup_audio, format="audio/mp3", autoplay=True)

elif selected_page == "å•è¯æœ¬":
    st.subheader(f"ğŸ““ æˆ‘çš„ç”Ÿè¯æœ¬ ({len(st.session_state.vocab)})")
    
    if not st.session_state.vocab:
        st.caption("æš‚æ— ç”Ÿè¯ï¼Œå¿«å»é˜…è¯»é¡µé¢æŸ¥è¯å§ï¼")
    else:
        # é¡¶éƒ¨å·¥å…·æ 
        c_tool1, c_tool2 = st.columns([1, 4])
        with c_tool1:
            if st.button("ğŸ“¤ å¯¼å‡º Anki åŒ…", type="primary"):
                # æ”¶é›†å‹¾é€‰çš„å•è¯
                selected_items = []
                for i, item in enumerate(st.session_state.vocab):
                    if st.session_state.get(f"chk_{i}", False):
                        selected_items.append(item)
                
                if not selected_items:
                    st.warning("è¯·å…ˆå‹¾é€‰è‡³å°‘ä¸€ä¸ªå•è¯ï¼")
                else:
                    # å¼‚æ­¥ç”Ÿæˆ
                    anki_io = asyncio.run(create_anki_package(selected_items, st.session_state.cfg))
                    st.download_button(
                        label="â¬‡ï¸ ç‚¹å‡»ä¸‹è½½ .apkg",
                        data=anki_io,
                        file_name=f"vocab_export_{datetime.now().strftime('%m%d')}.apkg",
                        mime="application/octet-stream"
                    )

        st.divider()
        
        # åˆ—è¡¨å¤´
        h1, h2, h3, h4, h5 = st.columns([0.5, 2, 3, 1, 1])
        h1.markdown("é€‰")
        h2.markdown("å•è¯")
        h3.markdown("é‡Šä¹‰ (ä¸­/ä¿„)")
        h4.markdown("å‘éŸ³")
        h5.markdown("æ“ä½œ")
        
        # åˆ—è¡¨å†…å®¹
        for i, item in enumerate(st.session_state.vocab):
            c1, c2, c3, c4, c5 = st.columns([0.5, 2, 3, 1, 1])
            with c1: st.checkbox("", key=f"chk_{i}")
            with c2: st.markdown(f"**{item['word']}**\n<br><span style='color:grey;font-size:12px'>{item.get('ipa','')}</span>", unsafe_allow_html=True)
            with c3: st.markdown(f"ğŸ‡¨ğŸ‡³ {item.get('zh','')}\n<br>ğŸ‡·ğŸ‡º {item.get('ru','')}", unsafe_allow_html=True)
            
            with c4:
                # æ’­æ”¾é€»è¾‘ï¼šç‚¹å‡»åå°†éŸ³é¢‘æ”¾å…¥ SessionState å¹¶åˆ·æ–°ï¼Œä¾é  autoplay æ’­æ”¾
                if st.button("ğŸ”Š", key=f"play_{i}"):
                    # ç®€æ˜“ç­–ç•¥ï¼šå¦‚æœæ˜¯ä¿„è¯­å•è¯ç”¨ä¿„è¯­å‘éŸ³ï¼Œå¦åˆ™é»˜è®¤è‹±è¯­
                    # è¿™é‡Œç®€å•åˆ¤æ–­ï¼šå¦‚æœå•è¯é‡Œæœ‰è¥¿é‡Œå°”å­—æ¯åˆ™ä¸ºä¿„è¯­
                    is_ru = bool(re.search('[Ğ°-ÑĞ-Ğ¯]', item['word']))
                    v_role = "ru-RU-DmitryNeural" if is_ru else "en-US-AriaNeural"
                    
                    audio_bytes, _ = asyncio.run(get_audio_bytes_mixed(item['word'], "Edge (æ¨è)", v_role, 0, st.session_state.cfg))
                    if audio_bytes:
                        st.session_state.vocab_audio_cache[item['word']] = audio_bytes
                        st.session_state.playing_word_idx = i # æ ‡è®°å½“å‰æ­£åœ¨æ’­æ”¾çš„ç´¢å¼•
                        st.rerun()

            with c5:
                if st.button("ğŸ—‘ï¸", key=f"del_{i}"):
                    st.session_state.vocab.pop(i)
                    save_vocab(st.session_state.vocab)
                    st.rerun()
            
            # ä»…åœ¨å½“å‰è¡Œæ¸²æŸ“ä¸å¯è§çš„éŸ³é¢‘æ’­æ”¾å™¨ä»¥è§¦å‘ Autoplay
            if st.session_state.playing_word_idx == i and item['word'] in st.session_state.vocab_audio_cache:
                st.audio(st.session_state.vocab_audio_cache[item['word']], format="audio/mp3", autoplay=True)